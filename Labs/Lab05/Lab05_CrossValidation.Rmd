---
title: 'STAA 577: Laboratory Five </br> `tidyverse` version'
author: 'Adapted by Tavener & Field </br> From: James, Witten, Hastie and Tibshirani'
date: "`r format(Sys.Date(), '%e %B %Y')`"
output:
  html_notebook:
    code_folding: show
    number_sections: yes
    toc: yes
    toc_float:
      collapsed: no
ratio: '9:16'
tables: yes
fontsize: 12pt
---

# Setup

```{r setup, messagel = FALSE, warning = FALSE}
options(warnPartialMatchArgs = FALSE)  # don't want these warnings
library(magrittr)     # pipes
library(tibble)       # tibbles
library(dplyr)        # data wrangling
library(boot)         # for `cv.glm`
library(purrr)        # iteration
library(ggplot2)      # tidy plotting
library(ISLR)         # Auto data set
```


---------------------------


# The `Auto` Data Set
```{r data, include = TRUE}
Auto %<>% as.tibble()
class(Auto)      # confirm now a tibble
names(Auto)      # which variables do we have?
Auto             # look at the top 10
Auto %>%         # Plot hp vs mpg
  ggplot(aes(x = horsepower, y = mpg)) +  # the relationship of this Lab
  geom_point(alpha = 0.5) +               # do scatter plot
  geom_smooth(method = 'loess')           # fit a polynomial smoothing function
```


------------------------------


# Cross-validation

```{r cv}
# Create a random partition into training and test sets
set.seed(1)
n     <- nrow(Auto)
train <- sample(1:n, n/2)    # random row indices; 50% data

# Fit linear model -> mpg as a function of hp
stats::lm(mpg ~ horsepower, data = Auto, subset = train)   # no polynomial

# Loop over polynomial power; note ^1 is same as above standard fit
# Return MSE on test set (-train)
purrr::map_dbl(1:5,
  ~stats::lm(mpg ~ stats::poly(horsepower, .x),
             data = Auto, subset = train) %>%  # fit lm
    predict(., Auto) %>%                 # predict on all samples
    magrittr::subtract(Auto$mpg) %>%     # obtain diffs from actual
    magrittr::raise_to_power(2) %>%      # Square differences
    magrittr::extract(-train) %>%        # ignore training predictions
    mean()                               # MSE
)

# Set a different random seed to create
# a different radnom train/test partition
set.seed(2)
train <- sample(1:n, n/2)    # random row indices; 50% data
purrr::map_dbl(1:5,
  ~stats::lm(mpg ~ stats::poly(horsepower, .x),
             data = Auto, subset = train) %>%  # fit lm
    predict(., Auto) %>%                 # predict on all samples
    magrittr::subtract(Auto$mpg) %>%     # obtain diffs from actual
    magrittr::raise_to_power(2) %>%      # Square differences
    magrittr::extract(-train) %>%        # ignore training predictions
    mean()                               # MSE
)
```


# Leave-One-Out CV via `boot::cv.glm`
```{r LOOCV}
# Linear regression using glm
glm_fit <- stats::glm(mpg ~ horsepower, data = Auto)
cv_err  <- boot::cv.glm(Auto, glm_fit)
cv_err$K            # Default K = n; i.e. LOOCV
cv_err$delta

# Loop over polynomial power
purrr::map_dbl(1:5, function(.x) {
  fit <- stats::glm(mpg ~ stats::poly(horsepower, .x), data = Auto)
  boot::cv.glm(Auto, fit) %>%
    purrr::pluck("delta") %>%    # pull out the `delta` element
    purrr::pluck(1)              # extract the first element of `delta`
})
```


-------------------------


# k-fold cross validation using `boot::cv.glm`
```{r k-fold_cross_validation}
set.seed(17)
# K-folds chosen at random; here K = 10
# Loop over polynomial power
# Question: why didn't we set the seed above in LOOCV?
purrr::map_dbl(1:10, function(.x) {
  fit <- stats::glm(mpg ~ stats::poly(horsepower, .x), data = Auto)
  boot::cv.glm(Auto, fit, K = 10) %>%
    purrr::pluck("delta") %>%
    purrr::pluck(1)
})
```


--------------------


# Bootstrap via `boot::boot`

Here we estimate the accuracy of a linear regression model via the bootstrap.
We will first define a function to fit a linear model of `mpg ~ horsepower`
given a dataset and a subset index (rows).
```{r bootstrap}
boot.fn <- function(data, index) {
  lm(mpg ~ horsepower, data = data, subset = index) %>%
    purrr::pluck("coefficients")
}

# Using all the data
boot.fn(Auto, 1:392)

# What does sample with replacement do?
# Sampling with replacement is what the bootstrap is all about!
sample(1:10, 10, replace = FALSE)
sample(1:10, 10, replace = TRUE)

# Make simulation reproducible
set.seed(1)

# First sample
sample(1:392, 392, replace = TRUE) %>% boot.fn(Auto, .)

# Second sample
sample(1:392, 392, replace = TRUE) %>% boot.fn(Auto, .)

# 1000 bootstrap samples; gets tedious, so use `boot::boot`
boot::boot(Auto, boot.fn, R = 1000)

# Compare Std. Error via `summary` function
# Empirical vs. Formula solution
# Differences indicate some assumptions may be broken
lm(mpg ~ horsepower, data = Auto) %>%
  summary() %>%
  purrr::pluck("coefficients")
```

## Tweak the linear model: use Quadratic
```{r boot2}
# Redefine boot.fn
boot.fn <- function(data, index) {
  lm(mpg ~ horsepower + I(horsepower^2), data = data, subset = index) %>%
    purrr::pluck("coefficients")
}

# Keep Reproducible
set.seed(1)
boot(Auto, boot.fn, 1000)

# Compare with standard error from linear regression
lm(mpg ~ horsepower + I(horsepower^2), data = Auto) %>%
  summary() %>%
  purrr::pluck("coefficients")
```






-------------------------

Created on `r Sys.Date()` by the [Rmarkdown package](https://github.com/rstudio/rmarkdown) (v`r utils::packageVersion("rmarkdown")`) and `r R.version$version.string`.
