---
title: 'STAA 577: Laboratory Seven (I) </br> `tidyverse` version'
author: 'Adapted by Tavener & Field </br> From: James, Witten, Hastie and Tibshirani'
date: "`r format(Sys.Date(), '%e %B %Y')`"
output:
  html_notebook:
    code_folding: show
    number_sections: yes
    toc: yes
    toc_float:
      collapsed: no
ratio: '9:16'
tables: yes
fontsize: 12pt
editor_options:
  chunk_output_type: inline
---



```{r setup, include = FALSE}
options(warnPartialMatchArgs = FALSE)  # don't want these warnings
library(magrittr)     # pipes
library(tibble)       # tibbles
library(dplyr)        # data wrangling
library(purrr)        # iteration
library(broom)        # summarizing models consistently
library(ggplot2)      # tidy plotting
library(ISLR)         # Wage data set
```


```{r data}
Wage %<>% as.tibble()     # convert to tibble
names(Wage)               # See variables available
Wage                      # look at tibble to see data
age      <- Wage$age      # make variable globally available downstream
wage     <- Wage$wage     # make variable globally available downstream
agelims  <- range(age)
age_grid <- seq(from = agelims[1], to = agelims[2])  # sequence from min to max
wage %>%                  # plot the distribution of the primary response variable of this lab
  data.frame() %>%        # convert to df for ggplot
  ggplot2::ggplot(aes(x = wage)) +
    ggplot2::geom_histogram(binwidth = 5)
```




# Polynomial Regression

```{r polynomial_regression}
# Regression using a basis of orthogonal polynomials of degree 4
fit <- stats::lm(wage ~ stats::poly(age, 4), data = Wage)
broom::tidy(fit)

# Fit using a basis of monomials up to degree 4
fit2 <- stats::lm(wage ~ stats::poly(age, 4, raw = TRUE), data = Wage)
broom::tidy(fit2)

# Are these the same?
preds  <- predict(fit, newdata = data.frame(age = age_grid), se = TRUE)
preds2 <- predict(fit2, newdata = data.frame(age = age_grid), se = TRUE)

# not *identical* but VERY close
identical(preds$fit, preds2$fit)       # identical() is a bit too strict
all.equal(preds$fit, preds2$fit, tolerance = 1e-10)   # use all.equal() with a tolerance
```


Here are two further ways of doing the same thing:

```{r more_examples}
fit2a <- stats::lm(wage ~ age + I(age^2) + I(age^3) + I(age^4), data = Wage)
fit2b <- stats::lm(wage ~ cbind(age, age^2, age^3, age^4), data = Wage)
all.equal(coef(fit2a), coef(fit2b), check.attributes = FALSE)
```



## Plot Age vs. Wage
Plotting with 2 standard error bands:

```{r plot_SEs}
fit_preds <- predict(fit, newdata = data.frame(age = age_grid), se = TRUE)
up        <- fit_preds$fit + 2 * fit_preds$se.fit
lo        <- fit_preds$fit - 2 * fit_preds$se.fit

# make df for ggplot
df_fit <- data.frame(     fit = fit_preds$fit,
                     age_grid = age_grid,
                           up = up,
                           lo = lo)

# pass `x` and `y` as df to ggplot
data.frame(age = age, wage = wage) %>%
  ggplot(aes(x = age, y = wage)) +
  geom_point(alpha = 0.25) +
  labs(title = "Degree-4 Polynomial") +
  geom_line(data = df_fit, aes(x = age_grid, y = fit), col = "blue") +
  geom_line(data = df_fit, aes(x = age_grid, y = up),
            col = "red", linetype = "dashed") +
  geom_line(data = df_fit, aes(x = age_grid, y = lo),
            col = "red", linetype = "dashed") +
  NULL        # neat trick that allows commenting layer lines above
              # without having to manage the `+` signs between layers
```




## Analysis of Variance I

Use ANOVA to estimate appropriate degree of polynomial (F-statistic)
**Note**: the models are *nested*.


```{r AoV1}
fit_1 <- stats::lm(wage ~ age, data = Wage)
fit_2 <- stats::lm(wage ~ poly(age, 2), data = Wage)
fit_3 <- stats::lm(wage ~ poly(age, 3), data = Wage)
fit_4 <- stats::lm(wage ~ poly(age, 4), data = Wage)
fit_5 <- stats::lm(wage ~ poly(age, 5), data = Wage)
anova(fit_1, fit_2, fit_3, fit_4, fit_5)

# Compare p-values (t-statistic) for coefficents of quintic fit
sumry <- broom::tidy(fit_5)
sumry

sumry %>%
  purrr::pluck("statistic") %>%    # pull out the `statistic` column
  magrittr::extract(3) %>%         # extract the 3rd entry
  magrittr::raise_to_power(2)      # Squared; plays nice with %>% operator
```



## Analysis of Variance II

```{r AoV2}
# Perform analysis of variance to determine model
fit_6 <- stats::lm(wage ~ education + age, data = Wage)
fit_7 <- stats::lm(wage ~ education + poly(age, 2), data = Wage)
fit_8 <- stats::lm(wage ~ education + poly(age, 3), data = Wage)
anova(fit_6, fit_7, fit_8)
```




---------------------------




# Polynomial Logistic Regression

```{r polynomial_logistic_regression}
polyLRfit   <- stats::glm(I(wage > 250) ~ poly(age, 4),
                          data = Wage, family = "binomial")
LRpreds <- predict(polyLRfit, newdata = data.frame(age = age_grid), se = TRUE)
upper   <- LRpreds$fit + 2 * LRpreds$se.fit        # logit space
lower   <- LRpreds$fit - 2 * LRpreds$se.fit        # logit space

# convert to linear space and df
lr_fit <- data.frame(
  age   = age_grid,
  pfit  = exp(LRpreds$fit) / (1 + exp(LRpreds$fit)),
  upper = exp(upper) / (1 + exp(upper)),
  lower = exp(lower) / (1 + exp(lower))
  ) %>%
  tibble::as.tibble()

# STU: check on this; why is this here? doesn't do anything
preds <- predict(polyLRfit, newdata = data.frame(age = age_grid),
                 type = "response", se = TRUE)

# pass `x` and `y` as df to ggplot
data.frame(age = age, y = I(wage > 250)/5) %>%
  ggplot(aes(x = age, y = y)) +
  geom_point(alpha = 0.25, size = 2.5) +
  #geom_jitter(height = 0) + # obscure binning effect; no vertical jitter
  ylim(c(0, 0.22)) +
  geom_line(data = lr_fit, aes(x = age, y = pfit), col = "blue") +
  labs(title = "Polynomial Logistic Regression with SE",
       y = "I(wage > 250)") +
  geom_line(data = lr_fit, aes(x = age, y = upper),
            col = "red", linetype = "dashed") +
  geom_line(data = lr_fit, aes(x = age, y = lower),
            col = "red", linetype = "dashed") +
  NULL

table(cut(age, 4))     # get no. obs per bin if split age into 4 groups

stats::lm(wage ~ cut(age, 4), data = Wage) %>%
  summary() %>%
  coef()
```
